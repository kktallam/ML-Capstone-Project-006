{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8e19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "   combined_equal_softmax.csv\n",
      "   combined_news_weighted_softmax.csv\n",
      "   combined_conf_weighted_softmax.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0. Config\n",
    "# -------------------------------------------------------------------\n",
    "INPUT_PATH = \"../data/scores_three_sources.csv\"  # or \"/mnt/data/scores_three_sources.csv\"\n",
    "OUTPUT_EQ   = \"combined_equal_softmax.csv\"\n",
    "OUTPUT_W    = \"combined_news_weighted_softmax.csv\"\n",
    "OUTPUT_CONF = \"combined_conf_weighted_softmax.csv\"\n",
    "\n",
    "sources = [\"Guard\", \"Ellen\", \"GNews\"]\n",
    "classes = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Load data\n",
    "# -------------------------------------------------------------------\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # drop any unnamed index cols\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Parse softmax strings -> separate columns per class\n",
    "# -------------------------------------------------------------------\n",
    "def parse_softmax_to_dict(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    try:\n",
    "        d = ast.literal_eval(s)\n",
    "        # normalize keys & default to 0 if missing\n",
    "        return {\n",
    "            \"positive\": float(d.get(\"positive\", 0.0)),\n",
    "            \"neutral\":  float(d.get(\"neutral\", 0.0)),\n",
    "            \"negative\": float(d.get(\"negative\", 0.0)),\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "for src in sources:\n",
    "    # Parse to dict\n",
    "    parsed = df[f\"{src}_softmax\"].apply(parse_softmax_to_dict)\n",
    "\n",
    "    # Create one column per class\n",
    "    for c in classes:\n",
    "        df[f\"{src}_{c}\"] = parsed.apply(\n",
    "            lambda d: d[c] if d is not None else np.nan\n",
    "        )\n",
    "\n",
    "    # Article counts as float (missing -> 0 for weighting)\n",
    "    df[f\"{src}_cnt\"] = df[f\"{src}_article_count\"].fillna(0.0)\n",
    "\n",
    "# Total article count across all sources (for output)\n",
    "df[\"total_article_count\"] = df[[f\"{src}_cnt\" for src in sources]].sum(axis=1)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Helper: combine probabilities row-wise\n",
    "# -------------------------------------------------------------------\n",
    "def combine_softmax_equal(row):\n",
    "    \"\"\"\n",
    "    Equal-weight average of available sources for each class.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for c in classes:\n",
    "        vals = [row[f\"{src}_{c}\"] for src in sources]\n",
    "        vals = [v for v in vals if pd.notna(v)]\n",
    "        if len(vals) == 0:\n",
    "            out[c] = np.nan\n",
    "        else:\n",
    "            out[c] = float(np.mean(vals))\n",
    "    # renormalize to sum to 1 if possible\n",
    "    total = sum(v for v in out.values() if pd.notna(v))\n",
    "    if not np.isnan(total) and total > 0:\n",
    "        out = {k: v / total for k, v in out.items()}\n",
    "    return out\n",
    "\n",
    "def combine_softmax_news_weighted(row):\n",
    "    \"\"\"\n",
    "    Article-count-weighted average with weights = log(1 + count).\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    weights = {src: np.log1p(row[f\"{src}_cnt\"]) for src in sources}\n",
    "\n",
    "    for c in classes:\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for src in sources:\n",
    "            p = row[f\"{src}_{c}\"]\n",
    "            w = weights[src]\n",
    "            if pd.notna(p) and w > 0:\n",
    "                num += w * p\n",
    "                den += w\n",
    "        if den == 0:\n",
    "            out[c] = np.nan\n",
    "        else:\n",
    "            out[c] = float(num / den)\n",
    "\n",
    "    # renormalize\n",
    "    total = sum(v for v in out.values() if pd.notna(v))\n",
    "    if not np.isnan(total) and total > 0:\n",
    "        out = {k: v / total for k, v in out.items()}\n",
    "    return out\n",
    "\n",
    "def combine_softmax_conf_weighted(row):\n",
    "    \"\"\"\n",
    "    Confidence-weighted:\n",
    "      weight = max_prob * log(1 + count) for each source.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    weights = {}\n",
    "    for src in sources:\n",
    "        probs = [row[f\"{src}_{c}\"] for c in classes]\n",
    "        if any(pd.notna(p) for p in probs):\n",
    "            max_prob = np.nanmax(probs)\n",
    "        else:\n",
    "            max_prob = np.nan\n",
    "        cnt = row[f\"{src}_cnt\"]\n",
    "        if pd.notna(max_prob) and cnt > 0:\n",
    "            weights[src] = float(max_prob * np.log1p(cnt))\n",
    "        else:\n",
    "            weights[src] = 0.0\n",
    "\n",
    "    for c in classes:\n",
    "        num = 0.0\n",
    "        den = 0.0\n",
    "        for src in sources:\n",
    "            p = row[f\"{src}_{c}\"]\n",
    "            w = weights[src]\n",
    "            if pd.notna(p) and w > 0:\n",
    "                num += w * p\n",
    "                den += w\n",
    "        if den == 0:\n",
    "            out[c] = np.nan\n",
    "        else:\n",
    "            out[c] = float(num / den)\n",
    "\n",
    "    # renormalize\n",
    "    total = sum(v for v in out.values() if pd.notna(v))\n",
    "    if not np.isnan(total) and total > 0:\n",
    "        out = {k: v / total for k, v in out.items()}\n",
    "    return out\n",
    "\n",
    "def probs_to_str(d):\n",
    "    \"\"\"\n",
    "    Convert dict of probs to string for CSV.\n",
    "    Returns NaN if any component is NaN.\n",
    "    \"\"\"\n",
    "    if d is None:\n",
    "        return np.nan\n",
    "    if any(pd.isna(v) for v in d.values()):\n",
    "        return np.nan\n",
    "    # ensure float conversion and fixed order\n",
    "    out = {\n",
    "        \"positive\": float(d[\"positive\"]),\n",
    "        \"neutral\":  float(d[\"neutral\"]),\n",
    "        \"negative\": float(d[\"negative\"]),\n",
    "    }\n",
    "    return str(out)\n",
    "\n",
    "def dict_to_class(d):\n",
    "    if d is None:\n",
    "        return np.nan\n",
    "    if any(pd.isna(v) for v in d.values()):\n",
    "        return np.nan\n",
    "    return max(d, key=d.get)  # argmax over positive/neutral/negative\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Build combined softmax for each method\n",
    "# -------------------------------------------------------------------\n",
    "eq_soft = df.apply(combine_softmax_equal, axis=1)\n",
    "w_soft  = df.apply(combine_softmax_news_weighted, axis=1)\n",
    "conf_soft = df.apply(combine_softmax_conf_weighted, axis=1)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Build output DataFrames (one row per dateâ€“entity)\n",
    "# -------------------------------------------------------------------\n",
    "out_eq = pd.DataFrame({\n",
    "    \"date\": df[\"date\"],\n",
    "    \"entity\": df[\"entity\"],\n",
    "    \"classification\": eq_soft.apply(dict_to_class),\n",
    "    \"softmax\": eq_soft.apply(probs_to_str),\n",
    "    \"article_count\": df[\"total_article_count\"],\n",
    "})\n",
    "\n",
    "out_w = pd.DataFrame({\n",
    "    \"date\": df[\"date\"],\n",
    "    \"entity\": df[\"entity\"],\n",
    "    \"classification\": w_soft.apply(dict_to_class),\n",
    "    \"softmax\": w_soft.apply(probs_to_str),\n",
    "    \"article_count\": df[\"total_article_count\"],\n",
    "})\n",
    "\n",
    "out_conf = pd.DataFrame({\n",
    "    \"date\": df[\"date\"],\n",
    "    \"entity\": df[\"entity\"],\n",
    "    \"classification\": conf_soft.apply(dict_to_class),\n",
    "    \"softmax\": conf_soft.apply(probs_to_str),\n",
    "    \"article_count\": df[\"total_article_count\"],\n",
    "})\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. Save to CSV\n",
    "# -------------------------------------------------------------------\n",
    "out_eq.to_csv(OUTPUT_EQ, index=False)\n",
    "out_w.to_csv(OUTPUT_W, index=False)\n",
    "out_conf.to_csv(OUTPUT_CONF, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", OUTPUT_EQ)\n",
    "print(\"  \", OUTPUT_W)\n",
    "print(\"  \", OUTPUT_CONF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29484416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
